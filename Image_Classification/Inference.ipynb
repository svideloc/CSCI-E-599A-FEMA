{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U_o64EXNIGUv"
      },
      "outputs": [],
      "source": [
        "# pip install datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tFvctWVsIUnJ"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch.utils.data import DataLoader, IterableDataset\n",
        "from transformers import AutoImageProcessor, AutoModelForImageClassification, AutoModel\n",
        "from sklearn.metrics import average_precision_score, precision_recall_fscore_support\n",
        "from tqdm import tqdm\n",
        "from torchvision import transforms\n",
        "import numpy as np\n",
        "import cv2\n",
        "from PIL import Image\n",
        "from datasets import load_dataset\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UZ44x3tXIYT9"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "\n",
        "# Mount Google Drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mEC0CWabfNoF"
      },
      "outputs": [],
      "source": [
        "# Define the classes of interest\n",
        "classes_of_interest = [\"flooding_any\", \"trees_damage\", \"buildings_minor_or_greater\"]\n",
        "\n",
        "# Define label keys\n",
        "label_keys = [\n",
        "    'bridges_any', 'buildings_any', 'buildings_affected_or_greater', 'buildings_minor_or_greater',\n",
        "    'debris_any', 'flooding_any', 'flooding_structures', 'roads_any', 'roads_damage',\n",
        "    'trees_any', 'trees_damage', 'water_any'\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XjtPLIdjfRmD"
      },
      "outputs": [],
      "source": [
        "# Define the dehazing function\n",
        "def haze_removal(image, omega=0.85, radius=10, epsilon=0.002):\n",
        "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY).astype(np.float32)\n",
        "    atmospheric_light = np.max(gray)\n",
        "    transmission = 1 - omega * cv2.erode(gray / atmospheric_light, np.ones((radius, radius), np.uint8))\n",
        "    transmission = np.clip(transmission, 0.1, 1.0)\n",
        "    refined_transmission = cv2.blur(transmission, (radius, radius))\n",
        "    dehazed = np.zeros_like(image, dtype=np.float32)\n",
        "    for i in range(3):\n",
        "        dehazed[:, :, i] = (image[:, :, i] - atmospheric_light) / refined_transmission + atmospheric_light\n",
        "    return np.clip(dehazed, 0, 255).astype(np.uint8)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zL1V7SIcfW8r"
      },
      "outputs": [],
      "source": [
        "# Load dataset\n",
        "dataset = load_dataset(\"MITLL/LADI-v2-dataset\", streaming=True, split=\"test\")\n",
        "\n",
        "# Map labels to indices\n",
        "label_to_index = {label: i for i, label in enumerate(label_keys)}\n",
        "\n",
        "# Extract images corresponding to the classes of interest\n",
        "def get_images_for_classes(dataset, classes, num_images=10):\n",
        "    selected_images = []\n",
        "    for example in dataset:\n",
        "        labels = [example[label] for label in label_keys]\n",
        "        if any(labels[label_to_index[class_name]] == 1 for class_name in classes):\n",
        "            selected_images.append(example[\"image\"])\n",
        "        if len(selected_images) >= num_images:\n",
        "            break\n",
        "    return selected_images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "su42fxggel2x"
      },
      "outputs": [],
      "source": [
        "# Get images for \"flooding_any\" and \"trees_damage\"\n",
        "test_images = get_images_for_classes(dataset, classes_of_interest, num_images=20)\n",
        "\n",
        "# Define transformations\n",
        "image_transforms = transforms.Compose([\n",
        "    transforms.Resize((384, 384)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "# Define the Custom DINOv2 Model with Dropout\n",
        "class CustomDINOv2WithDropout(nn.Module):\n",
        "    def __init__(self, base_model, num_labels, dropout_rate=0.3):\n",
        "        super(CustomDINOv2WithDropout, self).__init__()\n",
        "        self.base_model = base_model\n",
        "        self.dropout = nn.Dropout(dropout_rate)\n",
        "        self.classifier = nn.Linear(self.base_model.config.hidden_size, num_labels)\n",
        "\n",
        "    def forward(self, pixel_values):\n",
        "        outputs = self.base_model(pixel_values=pixel_values, output_hidden_states=False)\n",
        "        pooled_output = outputs.pooler_output\n",
        "        pooled_output = self.dropout(pooled_output)\n",
        "        logits = self.classifier(pooled_output)\n",
        "        return logits\n",
        "\n",
        "# Load the DINOv2 base model from Hugging Face\n",
        "base_model = AutoModel.from_pretrained(\"facebook/dinov2-base\")\n",
        "processor = AutoImageProcessor.from_pretrained(\"facebook/dinov2-base\")\n",
        "\n",
        "# Initialize the Custom Model\n",
        "num_labels = len(label_keys)\n",
        "dropout_rate = 0.4\n",
        "model = CustomDINOv2WithDropout(base_model=base_model, num_labels=num_labels, dropout_rate=dropout_rate)\n",
        "\n",
        "# Load the state dictionary from your saved checkpoint\n",
        "model_path = \"/content/drive/MyDrive/Classification/partially_dehazed_final_best_model.pth\"\n",
        "model.load_state_dict(torch.load(model_path))\n",
        "model.to(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.eval()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "PFtl4OxGoozE"
      },
      "outputs": [],
      "source": [
        "# Define the number of images per row\n",
        "images_per_row = 2\n",
        "\n",
        "# Preprocess and perform inference\n",
        "def preprocess_and_infer(image, model, apply_dehaze=False):\n",
        "    if apply_dehaze:\n",
        "        image = haze_removal(np.array(image))\n",
        "        image = Image.fromarray(image)\n",
        "\n",
        "    image_tensor = image_transforms(image).unsqueeze(0).to(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "    with torch.no_grad():\n",
        "        logits = model(image_tensor)\n",
        "        probs = torch.sigmoid(logits).cpu().numpy()[0]\n",
        "\n",
        "    return probs\n",
        "\n",
        "# Define a probability threshold\n",
        "probability_threshold = 0.4\n",
        "\n",
        "# Filter images based on predictions\n",
        "filtered_images = []\n",
        "for i, image in enumerate(test_images):\n",
        "    # Get class name\n",
        "    class_name = classes_of_interest[i % len(classes_of_interest)]\n",
        "\n",
        "    # Apply dehazing only for selected classes\n",
        "    apply_dehaze = class_name in [\"flooding_any\", \"trees_damage\"]  # Do not dehaze \"buildings_minor_or_greater\"\n",
        "\n",
        "    # Perform inference\n",
        "    probs = preprocess_and_infer(image, model=model, apply_dehaze=apply_dehaze)\n",
        "\n",
        "    # Check if the probability for the class of interest exceeds the threshold\n",
        "    class_prob = probs[label_to_index[class_name]]\n",
        "    if class_prob >= probability_threshold:\n",
        "        filtered_images.append((image, class_name, class_prob))\n",
        "\n",
        "# Display filtered images\n",
        "num_images = len(filtered_images)\n",
        "num_rows = (num_images + images_per_row - 1) // images_per_row  # Calculate total rows\n",
        "\n",
        "plt.figure(figsize=(15, num_rows * 5))  # Adjust figure size dynamically\n",
        "for i, (image, class_name, class_prob) in enumerate(filtered_images):\n",
        "    plt.subplot(num_rows, images_per_row, i + 1)\n",
        "    plt.imshow(image)\n",
        "    plt.title(f\"{class_name}: {class_prob:.2f}\")\n",
        "    plt.axis(\"off\")\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NplPrGzTtMpb"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}