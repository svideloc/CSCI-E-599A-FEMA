{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sX9j9RTFZct4"
      },
      "outputs": [],
      "source": [
        "# pip install optuna"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2bxWW_VyZjVl"
      },
      "outputs": [],
      "source": [
        "# pip install datasets"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import optuna\n",
        "import os\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch.utils.data import DataLoader, IterableDataset\n",
        "from transformers import AutoImageProcessor, AutoModelForImageClassification\n",
        "from sklearn.metrics import average_precision_score, precision_recall_fscore_support\n",
        "from tqdm import tqdm\n",
        "from torchvision import transforms\n",
        "import numpy as np\n",
        "import cv2\n",
        "from PIL import Image"
      ],
      "metadata": {
        "id": "cIE0HwOTamV1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "\n",
        "# Mount Google Drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Define the checkpoint directory and path\n",
        "checkpoint_dir = \"/content/drive/My Drive/Colab Checkpoints\"\n",
        "os.makedirs(checkpoint_dir, exist_ok=True)  # Create directory if it doesn't exist\n",
        "checkpoint_path = os.path.join(checkpoint_dir, \"checkpoint.pth\")"
      ],
      "metadata": {
        "id": "LoJdJFc9qtbA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Custom Model with Dropout\n",
        "class CustomDINOv2WithDropout(nn.Module):\n",
        "    def __init__(self, base_model, num_labels, dropout_rate=0.3):\n",
        "        super(CustomDINOv2WithDropout, self).__init__()\n",
        "        self.base_model = base_model\n",
        "        self.dropout = nn.Dropout(dropout_rate)\n",
        "        self.classifier = nn.Linear(self.base_model.config.hidden_size, num_labels)\n",
        "\n",
        "    def forward(self, pixel_values):\n",
        "        outputs = self.base_model(pixel_values=pixel_values, output_hidden_states=False)\n",
        "        pooled_output = outputs.pooler_output\n",
        "        pooled_output = self.dropout(pooled_output)\n",
        "        logits = self.classifier(pooled_output)\n",
        "        return logits\n",
        "\n",
        "# Multi-label Metrics\n",
        "def multi_label_metrics(logits, y_true, labels, threshold=0.5):\n",
        "    probs = torch.sigmoid(logits).cpu().numpy()\n",
        "    y_pred = probs > threshold\n",
        "\n",
        "    # Compute overall metrics\n",
        "    mean_prec, mean_rec, mean_f1, _ = precision_recall_fscore_support(\n",
        "        y_true=y_true, y_pred=y_pred, average=\"weighted\", zero_division=np.nan\n",
        "    )\n",
        "    mean_ap = average_precision_score(y_true, probs, average=\"weighted\")\n",
        "\n",
        "    # Compute label-wise metrics\n",
        "    precs, recs, f1s, _ = precision_recall_fscore_support(\n",
        "        y_true=y_true, y_pred=y_pred, average=None, zero_division=np.nan\n",
        "    )\n",
        "    aps = average_precision_score(y_true, probs, average=None)\n",
        "\n",
        "    # Combine metrics into a dictionary\n",
        "    metrics = {\n",
        "        \"mean_ap\": mean_ap,\n",
        "        \"mean_precision\": mean_prec,\n",
        "        \"mean_recall\": mean_rec,\n",
        "        \"mean_f1\": mean_f1,\n",
        "        \"label_aps\": {labels[i]: aps[i] for i in range(len(labels))},\n",
        "        \"label_f1s\": {labels[i]: f1s[i] for i in range(len(labels))}\n",
        "    }\n",
        "    return metrics\n",
        "\n",
        "\n",
        "# Haze Removal Function with Tunable Parameters\n",
        "def haze_removal(image, omega, radius, epsilon):\n",
        "    # Ensure the image is a NumPy array\n",
        "    if not isinstance(image, np.ndarray):\n",
        "        image = np.array(image)\n",
        "\n",
        "    # Convert image to grayscale\n",
        "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY).astype(np.float32)\n",
        "    atmospheric_light = np.max(gray)\n",
        "    transmission = 1 - omega * cv2.erode(gray / atmospheric_light, np.ones((radius, radius), np.uint8))\n",
        "    transmission = np.clip(transmission, 0.1, 1.0)\n",
        "\n",
        "    # Refine the transmission map using a basic box filter\n",
        "    refined_transmission = cv2.blur(transmission, (radius, radius))\n",
        "\n",
        "    # Dehaze the image\n",
        "    dehazed = np.zeros_like(image, dtype=np.float32)\n",
        "    for i in range(3):\n",
        "        dehazed[:, :, i] = (image[:, :, i] - atmospheric_light) / refined_transmission + atmospheric_light\n",
        "    return np.clip(dehazed, 0, 255).astype(np.uint8)\n",
        "\n",
        "# Dataset Class with Dehazing Enhancement for \"roads_damage\"\n",
        "from PIL import Image\n",
        "\n",
        "# Dataset Class with Selective Dehazing\n",
        "class StreamDatasetWithSelectiveEnhancement(IterableDataset):\n",
        "    def __init__(self, dataset, split_name, label_keys, image_transforms, omega, radius, epsilon):\n",
        "        self.dataset = dataset\n",
        "        self.split_name = split_name\n",
        "        self.label_keys = label_keys\n",
        "        self.image_transforms = image_transforms\n",
        "        self.omega = omega\n",
        "        self.radius = radius\n",
        "        self.epsilon = epsilon\n",
        "\n",
        "        # Indices of labels for selective dehazing\n",
        "        self.dehaze_labels = [\n",
        "            self.label_keys.index(\"roads_damage\"),\n",
        "            self.label_keys.index(\"flooding_structures\"),\n",
        "            self.label_keys.index(\"flooding_any\"),\n",
        "            self.label_keys.index(\"trees_damage\"),\n",
        "\n",
        "\n",
        "        ]\n",
        "\n",
        "    def process_item(self, item):\n",
        "        image = item[\"image\"]\n",
        "        labels = [int(item[key]) for key in self.label_keys]\n",
        "\n",
        "        # Ensure image is a NumPy array before processing\n",
        "        if not isinstance(image, np.ndarray):\n",
        "            image = np.array(image)\n",
        "\n",
        "        # Apply haze removal for specified labels only\n",
        "        if any(labels[label_idx] for label_idx in self.dehaze_labels):\n",
        "            image = haze_removal(image, self.omega, self.radius, self.epsilon)\n",
        "\n",
        "        # Convert the processed NumPy array back to a PIL Image\n",
        "        image = Image.fromarray(image)\n",
        "\n",
        "        # Apply transformations\n",
        "        processed_image = self.image_transforms(image)\n",
        "        processed_labels = torch.tensor(labels, dtype=torch.float32)\n",
        "        return processed_image, processed_labels\n",
        "\n",
        "    def __iter__(self):\n",
        "        for item in self.dataset[self.split_name]:\n",
        "            yield self.process_item(item)\n",
        "\n",
        "# Updated process_dataset Function\n",
        "def process_dataset(\n",
        "    model, dataset, split_name, label_keys, image_transforms, optimizer=None, train=False, batch_size=8, omega=None, radius=None, epsilon=None\n",
        "):\n",
        "    model.train() if train else model.eval()\n",
        "    running_loss = 0.0\n",
        "    all_logits, all_labels = [], []\n",
        "    batch_count = 0\n",
        "\n",
        "    # Use the enhanced dataset with selective dehazing\n",
        "    processed_dataset = StreamDatasetWithSelectiveEnhancement(\n",
        "        dataset, split_name, label_keys, image_transforms, omega=omega, radius=radius, epsilon=epsilon\n",
        "    )\n",
        "    loader = DataLoader(processed_dataset, batch_size=batch_size, collate_fn=lambda x: tuple(zip(*x)))\n",
        "\n",
        "    for batch_images, batch_labels in tqdm(loader, desc=\"Training\" if train else \"Validation\"):\n",
        "        batch_count += 1\n",
        "        batch_images, batch_labels = map(torch.stack, (batch_images, batch_labels))\n",
        "        batch_images, batch_labels = batch_images.to(device), batch_labels.to(device)\n",
        "\n",
        "        if train:\n",
        "            optimizer.zero_grad()\n",
        "            with torch.cuda.amp.autocast():\n",
        "                logits = model(batch_images)\n",
        "                loss = torch.nn.BCEWithLogitsLoss()(logits, batch_labels)\n",
        "            scaler.scale(loss).backward()\n",
        "            scaler.step(optimizer)\n",
        "            scaler.update()\n",
        "            running_loss += loss.item()\n",
        "        else:\n",
        "            with torch.no_grad():\n",
        "                logits = model(batch_images)\n",
        "                loss = torch.nn.BCEWithLogitsLoss()(logits, batch_labels)\n",
        "                running_loss += loss.item()\n",
        "\n",
        "        all_logits.append(logits.detach().cpu())\n",
        "        all_labels.append(batch_labels.detach().cpu())\n",
        "\n",
        "    all_logits = torch.cat(all_logits, dim=0)\n",
        "    all_labels = torch.cat(all_labels, dim=0)\n",
        "\n",
        "    return running_loss / batch_count, all_logits, all_labels\n",
        "\n",
        "def objective(trial):\n",
        "    global model, processor, device\n",
        "\n",
        "    # Hyperparameters to tune\n",
        "    lr = trial.suggest_float(\"lr\", 1e-6, 1e-3, log=True)\n",
        "    dropout_rate = trial.suggest_float(\"dropout_rate\", 0.1, 0.5)\n",
        "    batch_size = trial.suggest_int(\"batch_size\", 16, 64, step=16)\n",
        "\n",
        "    # Haze removal parameters\n",
        "    omega = trial.suggest_float(\"omega\", 0.8, 1.0)\n",
        "    radius = trial.suggest_int(\"radius\", 10, 20)\n",
        "    epsilon = trial.suggest_float(\"epsilon\", 0.0001, 0.01)\n",
        "\n",
        "    # Redefine the model with tuned dropout rate\n",
        "    model = CustomDINOv2WithDropout(base_model.base_model, num_labels=len(label_keys), dropout_rate=dropout_rate).to(device)\n",
        "    optimizer = torch.optim.AdamW(model.parameters(), lr=lr, weight_decay=1e-4)\n",
        "    scaler = torch.cuda.amp.GradScaler()\n",
        "\n",
        "    # Warm Start: Resume from checkpoint if it exists\n",
        "    start_epoch, best_val_map = 0, 0.0\n",
        "    if os.path.exists(checkpoint_path):\n",
        "        print(f\"Resuming training from checkpoint: {checkpoint_path}\")\n",
        "        checkpoint = torch.load(checkpoint_path)\n",
        "        model.load_state_dict(checkpoint[\"model_state_dict\"])\n",
        "        optimizer.load_state_dict(checkpoint[\"optimizer_state_dict\"])\n",
        "        scaler.load_state_dict(checkpoint[\"scaler_state_dict\"])\n",
        "        start_epoch = checkpoint[\"epoch\"] + 1\n",
        "        best_val_map = checkpoint[\"best_val_map\"]\n",
        "\n",
        "    # Training Loop\n",
        "    num_epochs = 5  # Shorter for tuning\n",
        "    patience, no_improvement = 3, 0\n",
        "\n",
        "    for epoch in range(start_epoch, num_epochs):\n",
        "        print(f\"Trial {trial.number}, Epoch {epoch + 1}/{num_epochs}\")\n",
        "\n",
        "        # Training\n",
        "        train_loss, _, _ = process_dataset(\n",
        "            model, ds, \"train\", label_keys, image_transforms, optimizer, train=True,\n",
        "            batch_size=batch_size, omega=omega, radius=radius, epsilon=epsilon\n",
        "        )\n",
        "        print(f\"Trial {trial.number}, Epoch {epoch + 1}: Train Loss = {train_loss:.4f}\")\n",
        "\n",
        "        # Validation\n",
        "        val_loss, val_logits, val_labels = process_dataset(\n",
        "            model, ds, \"validation\", label_keys, image_transforms, batch_size=batch_size,\n",
        "            omega=omega, radius=radius, epsilon=epsilon\n",
        "        )\n",
        "        val_metrics = multi_label_metrics(val_logits, val_labels.numpy(), label_keys)\n",
        "        print(f\"Validation Metrics (Trial {trial.number}, Epoch {epoch + 1}): {val_metrics}\")\n",
        "\n",
        "        # Display label-wise metrics for better visibility\n",
        "        print(f\"Label-wise APs (Trial {trial.number}, Epoch {epoch + 1}):\")\n",
        "        for label, ap in val_metrics[\"label_aps\"].items():\n",
        "            print(f\"  {label}: {ap:.4f}\")\n",
        "        print(f\"Label-wise F1 Scores (Trial {trial.number}, Epoch {epoch + 1}):\")\n",
        "        for label, f1 in val_metrics[\"label_f1s\"].items():\n",
        "            print(f\"  {label}: {f1:.4f}\")\n",
        "\n",
        "        # Log mean_ap for the trial\n",
        "        trial.report(val_metrics[\"mean_ap\"], epoch)\n",
        "        print(f\"Trial {trial.number}, Epoch {epoch + 1}: mean_ap = {val_metrics['mean_ap']:.4f}\")\n",
        "\n",
        "        # Save the best model of the trial\n",
        "        if val_metrics[\"mean_ap\"] > best_val_map:\n",
        "            best_val_map = val_metrics[\"mean_ap\"]\n",
        "            no_improvement = 0\n",
        "            torch.save(model.state_dict(), f\"{checkpoint_dir}/partially_dehazed_best_model_trial_{trial.number}.pth\")\n",
        "            print(f\"Best model saved for trial {trial.number} with mAP: {best_val_map:.4f}\")\n",
        "        else:\n",
        "            no_improvement += 1\n",
        "\n",
        "        # Save a checkpoint after every epoch\n",
        "        torch.save({\n",
        "            \"epoch\": epoch,\n",
        "            \"model_state_dict\": model.state_dict(),\n",
        "            \"optimizer_state_dict\": optimizer.state_dict(),\n",
        "            \"scaler_state_dict\": scaler.state_dict(),\n",
        "            \"best_val_map\": best_val_map,\n",
        "        }, checkpoint_path)\n",
        "        print(f\"Checkpoint saved at: {checkpoint_path}\")\n",
        "\n",
        "        # Early stopping\n",
        "        if no_improvement >= patience:\n",
        "            print(f\"Trial {trial.number}: Early stopping triggered.\")\n",
        "            break\n",
        "\n",
        "        torch.cuda.empty_cache()  # Clear memory to prevent fragmentation\n",
        "\n",
        "    return best_val_map\n",
        "\n",
        "\n",
        "# Load dataset\n",
        "from datasets import load_dataset\n",
        "ds = load_dataset(\"MITLL/LADI-v2-dataset\", streaming=True)\n",
        "\n",
        "# Define label keys\n",
        "label_keys = [\n",
        "    'bridges_any', 'buildings_any', 'buildings_affected_or_greater',\n",
        "    'buildings_minor_or_greater', 'debris_any', 'flooding_any',\n",
        "    'flooding_structures', 'roads_any', 'roads_damage', 'trees_any',\n",
        "    'trees_damage', 'water_any'\n",
        "]\n",
        "\n",
        "# Load DINOv2 model\n",
        "model_name = \"facebook/dinov2-base\"\n",
        "processor = AutoImageProcessor.from_pretrained(model_name)\n",
        "base_model = AutoModelForImageClassification.from_pretrained(\n",
        "    model_name, ignore_mismatched_sizes=True\n",
        ")\n",
        "\n",
        "# Define transformations\n",
        "image_transforms = transforms.Compose([\n",
        "    transforms.Resize((384, 384)),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "# Device and scaler\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "scaler = torch.cuda.amp.GradScaler()\n",
        "\n",
        "# Run Optuna Study\n",
        "study = optuna.create_study(direction=\"maximize\")\n",
        "study.optimize(objective, n_trials=2)\n",
        "\n",
        "# Print best hyperparameters\n",
        "print(\"Best hyperparameters:\", study.best_params)\n",
        "\n"
      ],
      "metadata": {
        "id": "SbrC6Cw7a8Fl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_with_best_params(best_params):\n",
        "    global model\n",
        "\n",
        "    # Extract best hyperparameters\n",
        "    lr = best_params[\"lr\"]\n",
        "    dropout_rate = best_params[\"dropout_rate\"]\n",
        "    batch_size = best_params[\"batch_size\"]\n",
        "    omega = best_params[\"omega\"]\n",
        "    radius = best_params[\"radius\"]\n",
        "    epsilon = best_params[\"epsilon\"]\n",
        "\n",
        "    # Redefine the model with the best dropout rate\n",
        "    model = CustomDINOv2WithDropout(base_model.base_model, num_labels=len(label_keys), dropout_rate=dropout_rate).to(device)\n",
        "    optimizer = torch.optim.AdamW(model.parameters(), lr=lr, weight_decay=1e-4)\n",
        "    scaler = torch.cuda.amp.GradScaler()\n",
        "\n",
        "    # Training loop\n",
        "    num_epochs = 15\n",
        "    patience = 3     # Number of epochs to wait for improvement\n",
        "    no_improvement = 0\n",
        "    best_val_map = 0.0\n",
        "    best_model_path = \"/content/partially_dehazed_final_best_model.pth\"\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        print(f\"Epoch {epoch + 1}/{num_epochs}\")\n",
        "\n",
        "        # Training\n",
        "        train_loss, _, _ = process_dataset(\n",
        "            model, ds, \"train\", label_keys, image_transforms, optimizer, train=True,\n",
        "            batch_size=batch_size, omega=omega, radius=radius, epsilon=epsilon\n",
        "        )\n",
        "        print(f\"Epoch {epoch + 1}: Train Loss = {train_loss:.4f}\")\n",
        "\n",
        "        # Validation\n",
        "        val_loss, val_logits, val_labels = process_dataset(\n",
        "            model, ds, \"validation\", label_keys, image_transforms, batch_size=batch_size,\n",
        "            omega=omega, radius=radius, epsilon=epsilon\n",
        "        )\n",
        "        val_metrics = multi_label_metrics(val_logits, val_labels.numpy(), label_keys)\n",
        "        print(f\"Validation Metrics (Epoch {epoch + 1}): {val_metrics}\")\n",
        "\n",
        "        # Display label-wise metrics for better visibility\n",
        "        print(f\"Label-wise APs (Epoch {epoch + 1}):\")\n",
        "        for label, ap in val_metrics[\"label_aps\"].items():\n",
        "            print(f\"  {label}: {ap:.4f}\")\n",
        "        print(f\"Label-wise F1 Scores (Epoch {epoch + 1}):\")\n",
        "        for label, f1 in val_metrics[\"label_f1s\"].items():\n",
        "            print(f\"  {label}: {f1:.4f}\")\n",
        "\n",
        "        # Save the best model\n",
        "        if val_metrics[\"mean_ap\"] > best_val_map:\n",
        "            best_val_map = val_metrics[\"mean_ap\"]\n",
        "            no_improvement = 0\n",
        "            torch.save(model.state_dict(), best_model_path)\n",
        "            print(f\"Best model saved for epoch {epoch + 1} with mAP: {best_val_map:.4f}\")\n",
        "        else:\n",
        "            no_improvement += 1\n",
        "\n",
        "        # Early stopping\n",
        "        if no_improvement >= patience:\n",
        "            print(f\"Early stopping triggered after {patience} epochs without improvement.\")\n",
        "            break\n",
        "\n",
        "        # Clear GPU cache\n",
        "        torch.cuda.empty_cache()\n",
        "\n",
        "    print(\"Training complete.\")\n",
        "    print(f\"Best validation mAP: {best_val_map:.4f}\")\n",
        "    print(f\"Best model saved to: {best_model_path}\")\n",
        "\n",
        "# Load the best parameters from Optuna and start training\n",
        "# train_with_best_params(study.best_params)\n",
        "train_with_best_params(study.best_params)"
      ],
      "metadata": {
        "id": "LTuZkDtejCJE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate on the test set using the final trained model\n",
        "print(\"Evaluating on the test set with the final trained model...\")\n",
        "\n",
        "# Ensure the model is in evaluation mode\n",
        "model.eval()\n",
        "\n",
        "# Process the test dataset\n",
        "test_loss, test_logits, test_labels = process_dataset(\n",
        "    model,\n",
        "    ds,\n",
        "    \"test\",\n",
        "    label_keys,\n",
        "    image_transforms,\n",
        "    batch_size=study.best_params[\"batch_size\"],\n",
        "    omega=study.best_params[\"omega\"],\n",
        "    radius=study.best_params[\"radius\"],\n",
        "    epsilon=study.best_params[\"epsilon\"]\n",
        ")\n",
        "\n",
        "# Compute test metrics\n",
        "test_metrics = multi_label_metrics(test_logits, test_labels.numpy(), label_keys)\n",
        "\n",
        "# Print overall test metrics\n",
        "print(f\"Test Loss: {test_loss:.4f}\")\n",
        "print(f\"Test Metrics:\")\n",
        "print(test_metrics)\n",
        "\n",
        "# Print label-wise metrics for detailed evaluation\n",
        "print(\"Label-wise APs on Test Set:\")\n",
        "for label, ap in test_metrics[\"label_aps\"].items():\n",
        "    print(f\"  {label}: {ap:.4f}\")\n",
        "\n",
        "print(\"Label-wise F1 Scores on Test Set:\")\n",
        "for label, f1 in test_metrics[\"label_f1s\"].items():\n",
        "    print(f\"  {label}: {f1:.4f}\")\n"
      ],
      "metadata": {
        "id": "pmKrsfaPQv4-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "5Xt0zkRLSCAs"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "L4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}